{
  "best_metric": 2.0876665075775236e-05,
  "best_model_checkpoint": "./results\\checkpoint-1500",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 6.1701202392578125,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 0.8496,
      "step": 10
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 1.7171299457550049,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.2712,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3327583074569702,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.045,
      "step": 30
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.10187233239412308,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.0098,
      "step": 40
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 0.040642935782670975,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0039,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.03473014011979103,
      "learning_rate": 4.9e-05,
      "loss": 0.0023,
      "step": 60
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 0.02623460441827774,
      "learning_rate": 4.883333333333334e-05,
      "loss": 0.0017,
      "step": 70
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.017560163512825966,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.0013,
      "step": 80
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.01579064317047596,
      "learning_rate": 4.85e-05,
      "loss": 0.0011,
      "step": 90
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.014851870015263557,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.001,
      "step": 100
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 0.013379046693444252,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 0.0009,
      "step": 110
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.009998835623264313,
      "learning_rate": 4.8e-05,
      "loss": 0.0008,
      "step": 120
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 0.009601103141903877,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 0.0006,
      "step": 130
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.00872681476175785,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0006,
      "step": 140
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0074710603803396225,
      "learning_rate": 4.75e-05,
      "loss": 0.0005,
      "step": 150
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.007265066262334585,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0005,
      "step": 160
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 0.006025063805282116,
      "learning_rate": 4.716666666666667e-05,
      "loss": 0.0004,
      "step": 170
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.006093102507293224,
      "learning_rate": 4.7e-05,
      "loss": 0.0004,
      "step": 180
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.005931196268647909,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.0004,
      "step": 190
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.0057425894774496555,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0003,
      "step": 200
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.004223463591188192,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0003,
      "step": 210
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.004652734380215406,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.0003,
      "step": 220
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 0.003979755565524101,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 0.0003,
      "step": 230
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.004776349291205406,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0003,
      "step": 240
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.004127928987145424,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.0003,
      "step": 250
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.0036131988745182753,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0002,
      "step": 260
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.0040087392553687096,
      "learning_rate": 4.55e-05,
      "loss": 0.0002,
      "step": 270
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.00342866824939847,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0002,
      "step": 280
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 0.0035123503766953945,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.0002,
      "step": 290
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.003004956990480423,
      "learning_rate": 4.5e-05,
      "loss": 0.0002,
      "step": 300
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 0.0028493087738752365,
      "learning_rate": 4.483333333333333e-05,
      "loss": 0.0002,
      "step": 310
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.0029710824601352215,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0002,
      "step": 320
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.0024365063291043043,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.002744341501966119,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.0002,
      "step": 340
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 0.0026623813901096582,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.0002,
      "step": 350
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.002343480009585619,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0002,
      "step": 360
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 0.0024316555354744196,
      "learning_rate": 4.383333333333334e-05,
      "loss": 0.0002,
      "step": 370
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.0025144917890429497,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0001,
      "step": 380
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0022906449157744646,
      "learning_rate": 4.35e-05,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.0022414131090044975,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 0.0020665721967816353,
      "learning_rate": 4.316666666666667e-05,
      "loss": 0.0001,
      "step": 410
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0020930878818035126,
      "learning_rate": 4.3e-05,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 0.002147287828847766,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.001988057279959321,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.0017912097973749042,
      "learning_rate": 4.25e-05,
      "loss": 0.0001,
      "step": 450
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.001853483496233821,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 0.0017074337229132652,
      "learning_rate": 4.216666666666667e-05,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0018754699267446995,
      "learning_rate": 4.2e-05,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 0.0018122034380212426,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.0016491663409397006,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.0017070405883714557,
      "learning_rate": 4.15e-05,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.0015106273349374533,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 0.001437098952010274,
      "learning_rate": 4.116666666666667e-05,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.001392716309055686,
      "learning_rate": 4.1e-05,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 0.0014507310697808862,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.0013477182947099209,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.0015273588942363858,
      "learning_rate": 4.05e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.001463333610445261,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 0.001409001532010734,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0014860831433907151,
      "learning_rate": 4e-05,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.0014573907246813178,
      "learning_rate": 3.983333333333333e-05,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.0014778837794438004,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.001286568003706634,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.001291948021389544,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 0.0012383656576275826,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.0001,
      "step": 650
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.0012009289348497987,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.0013822203036397696,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.0001,
      "step": 670
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.001250513014383614,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.0014037276851013303,
      "learning_rate": 3.85e-05,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.0011179657885804772,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 0.0010954056633636355,
      "learning_rate": 3.816666666666667e-05,
      "loss": 0.0001,
      "step": 710
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.001132897799834609,
      "learning_rate": 3.8e-05,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 0.0009616261813789606,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 0.0001,
      "step": 730
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.0011878934456035495,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.0010665487498044968,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.0011388161219656467,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 0.0010480221826583147,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0009335321374237537,
      "learning_rate": 3.7e-05,
      "loss": 0.0001,
      "step": 780
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 0.0010026836534962058,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.0001,
      "step": 790
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.0010716079268604517,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.001033563050441444,
      "learning_rate": 3.65e-05,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.0008567813201807439,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.0001,
      "step": 820
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 0.0010007262462750077,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 0.0001,
      "step": 830
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.0008508730097673833,
      "learning_rate": 3.6e-05,
      "loss": 0.0001,
      "step": 840
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 0.0008733360446058214,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.0008966878522187471,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.0008711057016626,
      "learning_rate": 3.55e-05,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.0008728668326511979,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 0.000935990537982434,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.000951584370341152,
      "learning_rate": 3.5e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 0.0007984492694959044,
      "learning_rate": 3.483333333333334e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.0007879601907916367,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.0009524350170977414,
      "learning_rate": 3.45e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.0007321126759052277,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.0008145422325469553,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0008795132162049413,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 0.0007261452847160399,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 0.0,
      "step": 970
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.00079828139860183,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0008200557786040008,
      "learning_rate": 3.35e-05,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.0007256194367073476,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 0.0007389304810203612,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.000757738365791738,
      "learning_rate": 3.3e-05,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 0.0007769987569190562,
      "learning_rate": 3.283333333333333e-05,
      "loss": 0.0,
      "step": 1030
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.0007213212666101754,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.0007031064596958458,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.0006810271297581494,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0,
      "step": 1060
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 0.0007145994459278882,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.0007389023085124791,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 0.0007534453179687262,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.0,
      "step": 1090
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.0008424524567089975,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.0006587021052837372,
      "learning_rate": 3.15e-05,
      "loss": 0.0,
      "step": 1110
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.0007160229724831879,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 0.0006819548434577882,
      "learning_rate": 3.116666666666667e-05,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.0007388149970211089,
      "learning_rate": 3.1e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 0.0006418385892175138,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.0006503958720713854,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.0007094336906448007,
      "learning_rate": 3.05e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.000586489390116185,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0,
      "step": 1180
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 0.0006893571699038148,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.0,
      "step": 1190
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0006188153056427836,
      "learning_rate": 3e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 0.000706759630702436,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 0.0,
      "step": 1210
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 0.0007144415867514908,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.0006079477025195956,
      "learning_rate": 2.95e-05,
      "loss": 0.0,
      "step": 1230
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.0006544319912791252,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.0005753919831477106,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0006144845974631608,
      "learning_rate": 2.9e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.0006603827350772917,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.000600441126152873,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.000620601000264287,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.0006140531040728092,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 0.0005453783669508994,
      "learning_rate": 2.816666666666667e-05,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0005605912301689386,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 0.0005685203359462321,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.0005680936155840755,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.0005532125942409039,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.0005034914938732982,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 0.0005445866263471544,
      "learning_rate": 2.716666666666667e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.000535793777089566,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 0.0005206982605159283,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.000554187165107578,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0005069805774837732,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0,
      "step": 1410
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.000523862021509558,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 0.0004999995580874383,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 0.0,
      "step": 1430
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0005793746677227318,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 0.0004986487911082804,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.0004926163237541914,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.0005552679067477584,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0,
      "step": 1470
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.0005234340787865222,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0,
      "step": 1480
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 0.000460759736597538,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.0,
      "step": 1490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0006809927872382104,
      "learning_rate": 2.5e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.0876665075775236e-05,
      "eval_runtime": 85.1872,
      "eval_samples_per_second": 70.433,
      "eval_steps_per_second": 4.402,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 185001621840000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
